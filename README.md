# ActionLSTM ‚Äì Human Action Recognition from 2D Skeletons (UCF101)

Este proyecto implementa un modelo de deep learning para la clasificaci√≥n de acciones humanas utilizando el dataset **UCF101 Skeleton 2D**, basado en coordenadas de 17 puntos clave (keypoints) por frame.

El sistema desarrollado incluye:
- Preprocesamiento de keypoints 2D
- Modelo **ActionLSTM** (LSTM bidireccional)
- Modelo **ActionMLP** (temporal pooling + MLP)
- Entrenamiento usando PyTorch
- Evaluaci√≥n cuantitativa del modelo
- Script de inferencia con nombres de clase para generar predicciones Top-5 

---

## üìÇ Estructura del proyecto

dataset/
‚îî‚îÄ‚îÄ ucf101_2d.pkl

checkpoints/
‚îî‚îÄ‚îÄ action_lstm_ucf101.pth
‚îî‚îÄ‚îÄ action_mlp_ucf101.pth

main.py   # Entrenamiento y evaluaci√≥n

inference.py   # Predicci√≥n (inferencias)

README.md

---

## üß† Modelos Implementados

### üîπ 1) **ActionLSTM (modelo principal)**   

ActionLSTM es un modelo basado en un LSTM bidireccional, dise√±ado para capturar dependencias temporales en secuencias de poses humanas.

**Caracter√≠sticas:**
- LSTM bidireccional  
- 2 capas recurrentes  
- 128 unidades ocultas  
- Dropout = 0.3  
- Entrada: secuencias de hasta 120 frames, cada frame con 51 features (x, y y score por articulaci√≥n)  
- Salida: 101 clases correspondientes al dataset UCF101  


### üîπ 2) **ActionMLP (baseline adicional)**  

Implementado para comparar arquitecturas del proyecto.

**Caracter√≠sticas:**
- Pooling temporal sobre todos los frames v√°lidos  
- MLP de dos capas  
- Dropout = 0.3  
- R√°pido y eficiente, pero sin modelar temporalidad  

Sirve para ver claramente las ventajas del LSTM.

---


## üìä Resultados obtenidos

Los dos modelos se entrenaron durante 20 √©pocas usando el split oficial `train1/test1`.

### **Resumen de m√©tricas**

| Modelo         | Arquitectura              | Accuracy Test | Accuracy Train |
|----------------|---------------------------|----------------|----------------|
| Aleatorio      | Predicci√≥n uniforme       | 0.99%         | ‚Äî              |
| **ActionMLP**  | MLP con pooling temporal  | **28.1%**     | 31%            |
| **ActionLSTM** | LSTM bidireccional        | **31%**       | 50%            |

**Conclusiones:**
- Ambos modelos superan ampliamente al baseline aleatorio.  
- El LSTM obtiene mejor desempe√±o al capturar dependencias temporales.  
- El MLP ofrece una comparaci√≥n s√≥lida y valida experimentalmente la elecci√≥n del LSTM como arquitectura principal.  

---

## üîç Inferencia con nombres de clase

El script `inference.py` muestra predicciones reales con nombres de clase:

---

## üöÄ C√≥mo entrenar el modelo

Ejecuta en la terminal:

`python main.py`

Para elegir el modelo se tendr√° que cambiar el par√°metro `MODEL_TYPE` dentro de `main.py`.

Los pesos del modelo entrenado se guardar√°n dependiendo del modelo utilizado:

`checkpoints/action_lstm_ucf101.pth`
`checkpoints/action_mlp_ucf101.pth`

---

## üîç C√≥mo ejecutar inferencias

Ejecuta:

 `python inference.py`

- Para probar diferentes videos del conjunto de prueba, cambia el par√°metro `idx` dentro de `inference.py`.
- Para elegir el modelo que utilizar√° `inference.py` se tendr√° que cambiar el par√°metro `MODEL_TYPE` dentro de `main.py`.

---

## üì¶ Dependencias necesarias

Instala las librer√≠as requeridas:

 `pip install torch numpy tqdm scikit-learn`

---

## üìå Posibles mejoras futuras

- Usar Graph Convolutional Networks (GCN) para modelar relaciones entre articulaciones.
- Implementar Transformers temporales (TimeSformer, PoseFormer).
- Modelos h√≠bridos CNN + LSTM
- Aplicar data augmentation temporal (jittering, frame dropping, scaling).
- Ajustar hiperpar√°metros y realizar fine-tuning espec√≠fico por categor√≠a.
- Entrenar modelos pre-entrenados en esqueletos como ST-GCN.

---

## üìÑ Licencia

Proyecto desarrollado con fines acad√©micos dentro del m√≥dulo de Deep Learning.





